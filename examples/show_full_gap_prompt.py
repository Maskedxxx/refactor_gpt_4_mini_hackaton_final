# examples/show_full_gap_prompt.py
# --- agent_meta ---
# role: gap-analyzer-prompt-demo
# owner: @backend
# contract: –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ GAP-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (system + user) –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
# last_reviewed: 2025-08-15
# interfaces:
#   - main(): –ø–µ—á–∞—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è gap_analyzer.v1
# --- /agent_meta ---

from __future__ import annotations

import json
from pathlib import Path

from src.models import ResumeInfo, VacancyInfo
from src.llm_gap_analyzer import LLMGapAnalyzerGenerator, GapAnalyzerOptions


def load_test_data() -> tuple[ResumeInfo, VacancyInfo]:
    data_dir = Path(__file__).parent.parent / "tests" / "data"
    with (data_dir / "simple_resume.json").open("r", encoding="utf-8") as f:
        resume = ResumeInfo(**json.load(f))
    with (data_dir / "simple_vacancy.json").open("r", encoding="utf-8") as f:
        vacancy = VacancyInfo(**json.load(f))
    return resume, vacancy


async def build_prompt_demo(prompt_version: str = "gap_analyzer.v1", include_summary: bool = True):
    print(f"=== GAP Analyzer ‚Äî –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ ({prompt_version}) ===\n")

    resume, vacancy = load_test_data()
    generator = LLMGapAnalyzerGenerator()
    options = GapAnalyzerOptions(
        prompt_version=prompt_version,
        language="ru",
        temperature=0.2,
        include_skill_match_summary=include_summary,
        extra_context={
            "user_notes": "–û–±—Ä–∞—Ç–∏—Ç—å –æ—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ Python –∏ FastAPI –æ–ø—ã—Ç",
            "priority_areas": ["—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏", "–æ–ø—ã—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ API"],
            "custom_focus": "–ò—Å–∫–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ–µ–∫—Ç–∞—Ö"
        }
    )

    # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é —Å–±–æ—Ä–∫—É –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (–±–µ–∑ –≤—ã–∑–æ–≤–∞ LLM)
    merged = generator._merge_with_defaults(options)  # type: ignore[attr-defined]
    prompt = await generator._build_prompt(resume, vacancy, merged)  # type: ignore[attr-defined]

    print("=" * 80)
    print("üéØ SYSTEM PROMPT:")
    print("=" * 80)
    print(prompt.system)
    print()

    print("=" * 80)
    print("üéØ USER PROMPT:")
    print("=" * 80)
    print(prompt.user[:20000] + "..." if len(prompt.user or "") > 20000 else prompt.user)
    print()

    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"System prompt: {len(prompt.system or '')} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"User prompt: {len(prompt.user or '')} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {len((prompt.system or '') + (prompt.user or ''))} —Å–∏–º–≤–æ–ª–æ–≤")


def main():
    import asyncio
    asyncio.run(build_prompt_demo())


if __name__ == "__main__":
    main()

